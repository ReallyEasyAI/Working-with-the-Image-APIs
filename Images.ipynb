{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univeral Code Used for the Entire Notebook\n",
    "\n",
    "Let's set up our libraries and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import requests  # For making HTTP requests\n",
    "import base64  # For encoding and decoding binary data to ASCII\n",
    "from openai import OpenAI  # Importing the OpenAI class from the openai module\n",
    "from IPython.display import Image, display, HTML  # For displaying images and HTML in Jupyter notebooks\n",
    "from PIL import Image as PILImage  # Importing the Image class from PIL and renaming it to avoid conflict with IPython.display.Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generations\n",
    "\n",
    "### Simple Generation\n",
    "The image generations endpoint allows you to create an original image given a text prompt. \n",
    "\n",
    "DALL-E 2 will allow for the following three sizes: 256x256, 512x512, or 1024x1024. \n",
    "\n",
    "DALL·E 3, images can have a size of 1024x1024, 1024x1792 or 1792x1024 pixels.\n",
    "\n",
    "By default, images are generated at standard quality, but when using DALL·E 3 you can set quality: \"hd\" for enhanced detail. Square, standard quality images are the fastest to generate.\n",
    "\n",
    "You can request 1 image at a time with DALL·E 3 (request more by making parallel requests) or up to 10 images at a time using DALL·E 2 with the n parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an image using the OpenAI client\n",
    "# Defaults to the DALL-E 2 model\n",
    "image = client.images.generate(\n",
    "    prompt=\"a shark in a suit inside the NYSE trading floor\",\n",
    ")\n",
    "\n",
    "# Extract the URL of the generated image\n",
    "image_url = image.data[0].url\n",
    "\n",
    "# Display the image URL and the image itself\n",
    "print(f\"Image URL: {image_url}\")\n",
    "display(Image(url=image_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Parameter Generation\n",
    "\n",
    "When creating an image you can have the following parameters:\n",
    "\n",
    "**prompt**  \n",
    "*string*  \n",
    "\n",
    "Required  \n",
    "A text description of the desired image(s). The maximum length is 1000 characters for dall-e-2 and 4000 characters for dall-e-3.\n",
    "\n",
    "**model**  \n",
    "*string*  \n",
    "\n",
    "Optional  \n",
    "Defaults to dall-e-2  \n",
    "The model to use for image generation.\n",
    "\n",
    "**n**  \n",
    "*integer* or *null*  \n",
    "\n",
    "Optional  \n",
    "Defaults to 1  \n",
    "The number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.\n",
    "\n",
    "**quality**  \n",
    "*string*  \n",
    "\n",
    "Optional  \n",
    "Defaults to standard  \n",
    "The quality of the image that will be generated. hd creates images with finer details and greater consistency across the image. This param is only supported for dall-e-3.\n",
    "\n",
    "**response_format**  \n",
    "*string* or *null*  \n",
    "\n",
    "Optional  \n",
    "Defaults to url  \n",
    "The format in which the generated images are returned. Must be one of url or b64_json. URLs are only valid for 60 minutes after the image has been generated.\n",
    "\n",
    "**size**  \n",
    "*string* or *null*  \n",
    "\n",
    "Optional  \n",
    "Defaults to 1024x1024  \n",
    "The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 for dall-e-2. Must be one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3 models.\n",
    "\n",
    "**style**  \n",
    "*string* or *null*  \n",
    "\n",
    "Optional  \n",
    "Defaults to vivid  \n",
    "The style of the generated images. Must be one of vivid or natural. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for dall-e-3.\n",
    "\n",
    "**user**  \n",
    "*string*  \n",
    "\n",
    "Optional  \n",
    "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an image using the OpenAI client with full parameters\n",
    "image_full_parameters = client.images.generate(\n",
    "    prompt=\"a shark in a suit inside the NYSE trading floor\",  # Description of the image to generate\n",
    "    model=\"dall-e-3\",  # Specify the model to use\n",
    "    n=1,  # Number of images to generate\n",
    "    quality=\"standard\",  # Quality of the generated image\n",
    "    response_format=\"url\",  # Format of the response (URL of the image)\n",
    "    size=\"1024x1024\",  # Size of the generated image\n",
    "    style=\"natural\",  # Style of the image\n",
    "    user=\"user-id-123\"  # User identifier for tracking purposes\n",
    ")\n",
    "\n",
    "# Extract the URL of the generated image\n",
    "image_url = image_full_parameters.data[0].url\n",
    "\n",
    "# Display the image URL and the image itself\n",
    "print(f\"Image URL: {image_url}\")\n",
    "display(Image(url=image_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Images (DALL-E 2 Only)\n",
    "\n",
    "Only the DALL-E 2 model currently supports creating more than one image at a time. To use this feature just indicate the correct model and then change \"n\" to the number of copies you want up to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple images using the OpenAI client with specified parameters\n",
    "images = client.images.generate(\n",
    "    prompt=\"a pitbull dog\",  # Description of the images to generate\n",
    "    model=\"dall-e-2\",  # Specify the model to use\n",
    "    n=10,  # Number of images to generate\n",
    "    quality=\"standard\",  # Quality of the generated images\n",
    "    response_format=\"url\",  # Format of the response (URLs of the images)\n",
    "    size=\"256x256\",  # Size of the generated images\n",
    "    style=\"natural\",  # Style of the images\n",
    "    user=\"user-id-123\"  # User identifier for tracking purposes\n",
    ")\n",
    "\n",
    "# Extract URLs from the responses and create HTML for displaying the images\n",
    "html = \"\"\n",
    "for image in images.data:\n",
    "    image_url = image.url  # Access the URL from the Image object\n",
    "    html += f'<img src=\"{image_url}\" style=\"display:inline; margin:10px; width:256px; height:256px;\">'\n",
    "    print(f\"{image_url}\\n\")  # Print the URL of each image\n",
    "\n",
    "# Display the images side by side in the notebook\n",
    "display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the Revised Prompt\n",
    "\n",
    "With the release of DALL·E 3, the model now takes in the default prompt provided and automatically re-write it for safety reasons, and to add more detail (more detailed prompts generally result in higher quality images).\n",
    "\n",
    "While it is not currently possible to disable this feature, you can use prompting to get outputs closer to your requested image by adding the following to your prompt: I NEED to test how the tool works with extremely simple prompts. DO NOT add any detail, just use it AS-IS:.\n",
    "\n",
    "The updated prompt is visible in the revised_prompt field of the data response object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt for image generation\n",
    "prompt = \"a shark in a suit inside the NYSE trading floor\"\n",
    "\n",
    "# Generate an image using the OpenAI client with full parameters\n",
    "image_full_parameters = client.images.generate(\n",
    "    prompt=prompt,  # Description of the image to generate\n",
    "    model=\"dall-e-3\",  # Specify the model to use\n",
    "    n=1,  # Number of images to generate\n",
    "    quality=\"standard\",  # Quality of the generated image\n",
    "    response_format=\"url\",  # Format of the response (URL of the image)\n",
    "    size=\"1024x1024\",  # Size of the generated image\n",
    "    style=\"natural\",  # Style of the image\n",
    "    user=\"user-id-123\"  # User identifier for tracking purposes\n",
    ")\n",
    "\n",
    "# Extract the URL of the generated image\n",
    "image_url = image_full_parameters.data[0].url\n",
    "\n",
    "# Show the original and revised prompts\n",
    "print(\"Original Prompt:\")\n",
    "print(prompt)\n",
    "print(\"\\nRevised Prompt:\")\n",
    "print(image_full_parameters.data[0].revised_prompt)\n",
    "\n",
    "# Display the image URL and the image itself\n",
    "print(f\"\\nImage URL: {image_url}\")\n",
    "display(Image(url=image_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overriding the Revised Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt for image generation\n",
    "prompt = (\n",
    "    \"I NEED to test how the tool works with extremely simple prompts. \"\n",
    "    \"DO NOT add any detail, just use it AS-IS: a shark in a suit inside the NYSE trading floor\"\n",
    ")\n",
    "\n",
    "# Generate an image using the OpenAI client with full parameters\n",
    "image_full_parameters = client.images.generate(\n",
    "    prompt=prompt,  # Description of the image to generate\n",
    "    model=\"dall-e-3\",  # Specify the model to use\n",
    "    n=1,  # Number of images to generate\n",
    "    quality=\"standard\",  # Quality of the generated image\n",
    "    response_format=\"url\",  # Format of the response (URL of the image)\n",
    "    size=\"1024x1024\",  # Size of the generated image\n",
    "    style=\"natural\",  # Style of the image\n",
    "    user=\"user-id-123\"  # User identifier for tracking purposes\n",
    ")\n",
    "\n",
    "# Extract the URL of the generated image\n",
    "image_url = image_full_parameters.data[0].url\n",
    "\n",
    "# Show the original and revised prompts\n",
    "print(\"Original Prompt:\")\n",
    "print(prompt)\n",
    "print(\"\\nRevised Prompt:\")\n",
    "print(image_full_parameters.data[0].revised_prompt)\n",
    "\n",
    "# Display the image URL and the image itself\n",
    "print(f\"\\nImage URL: {image_url}\")\n",
    "display(Image(url=image_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Images\n",
    "\n",
    "You can download the images from URLs or from Base64 output for preserving the images you have made.\n",
    "\n",
    "**NOTE: URL images are only good for ONE HOUR before they expire**\n",
    "\n",
    "### Download with a URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an image using the OpenAI client with full parameters\n",
    "image_full_parameters = client.images.generate(\n",
    "    prompt=\"a cabin on a snowy hillside at night\",  # Description of the image to generate\n",
    "    model=\"dall-e-3\",  # Specify the model to use\n",
    "    n=1,  # Number of images to generate\n",
    "    quality=\"standard\",  # Quality of the generated image\n",
    "    response_format=\"url\",  # Format of the response (URL of the image)\n",
    "    size=\"1024x1024\",  # Size of the generated image\n",
    "    style=\"natural\",  # Style of the image\n",
    "    user=\"user-id-123\"  # User identifier for tracking purposes\n",
    ")\n",
    "\n",
    "# Extract the URL of the generated image\n",
    "image_url = image_full_parameters.data[0].url\n",
    "\n",
    "# Display the image\n",
    "display(Image(url=image_url))\n",
    "\n",
    "# Download the image\n",
    "image_data = requests.get(image_url).content\n",
    "\n",
    "# Save the image to a file\n",
    "with open('snowy_cabin.png', 'wb') as handler:\n",
    "    handler.write(image_data)\n",
    "\n",
    "print(\"Image downloaded and saved as 'snowy_cabin.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a Base64 Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an image using the OpenAI client with full parameters\n",
    "image_full_parameters = client.images.generate(\n",
    "    prompt=\"a cabin on a snowy hillside at night\",  # Description of the image to generate\n",
    "    model=\"dall-e-3\",  # Specify the model to use\n",
    "    n=1,  # Number of images to generate\n",
    "    quality=\"standard\",  # Quality of the generated image\n",
    "    response_format=\"b64_json\",  # Format of the response (Base64 encoded JSON)\n",
    "    size=\"1024x1024\",  # Size of the generated image\n",
    "    style=\"natural\",  # Style of the image\n",
    "    user=\"user-id-123\"  # User identifier for tracking purposes\n",
    ")\n",
    "\n",
    "# Get the Base64 image data from the response\n",
    "b64_image = image_full_parameters.data[0].b64_json\n",
    "\n",
    "# Decode the Base64 image data to binary\n",
    "image_data = base64.b64decode(b64_image)\n",
    "\n",
    "# Display the image in the notebook\n",
    "display(Image(data=image_data))\n",
    "\n",
    "# Save the image to a file\n",
    "with open('b64_snowy_cabin.png', 'wb') as handler:\n",
    "    handler.write(image_data)\n",
    "\n",
    "print(\"Image displayed and saved as 'b64_snowy_cabin.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing Images (DALL-E 2 Only)\n",
    "\n",
    "Also known as \"inpainting\", the image edits endpoint allows you to edit or extend an image by uploading an image and mask indicating which areas should be replaced. The transparent areas of the mask indicate where the image should be edited, and the prompt should describe the full new image, not just the erased area. This endpoint can enable experiences like DALL·E image editing in ChatGPT Plus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an image using the OpenAI client with full parameters\n",
    "image_full_parameters = client.images.generate(\n",
    "    prompt=\"a pool with a nice house in the background\",  # Description of the image to generate\n",
    "    model=\"dall-e-2\",  # Specify the model to use\n",
    "    n=1,  # Number of images to generate\n",
    "    quality=\"standard\",  # Quality of the generated image\n",
    "    response_format=\"url\",  # Format of the response (URL of the image)\n",
    "    size=\"1024x1024\",  # Size of the generated image\n",
    "    style=\"natural\",  # Style of the image\n",
    "    user=\"user-id-123\"  # User identifier for tracking purposes\n",
    ")\n",
    "\n",
    "# Extract the URL of the generated image\n",
    "image_url = image_full_parameters.data[0].url\n",
    "\n",
    "# Display the image in the notebook\n",
    "display(Image(url=image_url))\n",
    "\n",
    "# Download the image from the URL\n",
    "image_data = requests.get(image_url).content\n",
    "\n",
    "# Save the image to a file\n",
    "with open('pool_original.png', 'wb') as handler:\n",
    "    handler.write(image_data)\n",
    "\n",
    "print(\"Image downloaded and saved as 'pool_original.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the original image using PIL\n",
    "original_image = PILImage.open(\"pool_original.png\")\n",
    "\n",
    "# Convert the image to RGBA format (adds an alpha channel)\n",
    "rgba_image = original_image.convert(\"RGBA\")\n",
    "\n",
    "# Save the converted image to a new file\n",
    "rgba_image.save(\"pool_rgba.png\")\n",
    "\n",
    "print(\"Original image converted to RGBA format and saved as 'pool_rgba.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the converted image in your API request to edit the image\n",
    "response = client.images.edit(\n",
    "    image=open(\"pool_rgba.png\", \"rb\"),  # Open the converted image file in binary mode\n",
    "    mask=open(\"pool_rgba_mask.png\", \"rb\"),  # Open the mask image file in binary mode\n",
    "    prompt=\"add a flamingo toy to the water\",  # Description of the edit to make\n",
    "    n=1,  # Number of edited images to generate\n",
    "    size=\"1024x1024\"  # Size of the edited image\n",
    ")\n",
    "\n",
    "# Print the API response for debugging purposes\n",
    "print(response)\n",
    "\n",
    "# Get the URL of the generated image\n",
    "image_url = response.data[0].url\n",
    "\n",
    "# Display the edited image\n",
    "display(Image(url=image_url))\n",
    "\n",
    "print(\"Edited image with a flamingo toy added to the water has been displayed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations (DALL-E 2 Only)\n",
    "\n",
    "Variations in the context of image generation refer to the process of creating multiple different versions of an image based on a single initial prompt. \n",
    "\n",
    "Variations allow for multiple interpretations of the same prompt, which enhances creativity and provides a range of artistic possibilities. Each generated image may exhibit different styles, compositions, and details, offering a broader spectrum of visual outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variation of the image using the OpenAI client\n",
    "response = client.images.create_variation(\n",
    "    model=\"dall-e-2\",  # Specify the model to use\n",
    "    image=open(\"pool_rgba.png\", \"rb\"),  # Open the image file in binary mode\n",
    "    n=1,  # Number of variations to generate\n",
    "    size=\"1024x1024\"  # Size of the generated image\n",
    ")\n",
    "\n",
    "# Extract the URL of the generated variation\n",
    "image_url = response.data[0].url\n",
    "\n",
    "# Display the original image\n",
    "display(Image(filename=\"pool_rgba.png\"))\n",
    "\n",
    "# Display the generated variation of the image\n",
    "display(Image(url=image_url))\n",
    "\n",
    "print(\"Original image and its variation have been displayed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
